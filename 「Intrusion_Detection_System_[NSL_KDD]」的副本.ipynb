{
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 394223,
          "sourceType": "datasetVersion",
          "datasetId": 174616
        }
      ],
      "dockerImageVersionId": 30698,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wuphwu/IDS/blob/main/%E3%80%8CIntrusion_Detection_System_%5BNSL_KDD%5D%E3%80%8D%E7%9A%84%E5%89%AF%E6%9C%AC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "import kagglehub\n",
        "hassan06_nslkdd_path = kagglehub.dataset_download('hassan06/nslkdd')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "J7nahT0NbIcF",
        "outputId": "dcf19692-1400-4b6c-c319-5e4fbd3a5107",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data source import complete.\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exploring the NSL-KDD Dataset: A Comprehensive Analysis About Intrusion Detection System\n",
        "\n",
        "## Introduction\n",
        "\n",
        "In the realm of cybersecurity and network intrusion detection, the NSL-KDD dataset stands as a benchmark for evaluating machine learning models' performance. This dataset, derived from the original KDD Cup 1999 dataset, addresses the limitations and biases present in its predecessor, making it a vital resource for researchers and practitioners in the field of Intrusion Detection System (IDS).\n",
        "\n",
        "This notebook embarks on a comprehensive exploration of the NSL-KDD dataset, focusing on building and evaluating machine learning models for intrusion detection. The key objectives of this project include:\n",
        "\n",
        "1. **Importing Libraries:** Essential Python libraries such as pandas, numpy, matplotlib, seaborn, and scikit-learn are imported to facilitate data manipulation, visualization, and model building.\n",
        "\n",
        "2. **Reading Dataset:** The NSL-KDD dataset is loaded into the environment, laying the foundation for subsequent analyses and model development.\n",
        "\n",
        "3. **Data Cleaning:** Data cleaning operations address missing values, handle outliers, and ensure the dataset's integrity, preparing it for exploratory data analysis (EDA) and preprocessing stages.\n",
        "\n",
        "4. **EDA and Visualization:** Exploratory data analysis and visualization techniques provide insights into the dataset's structure, feature distribution, correlations, and potential patterns, aiding in understanding network traffic and intrusion behaviors.\n",
        "\n",
        "5. **Preprocessing:** Preprocessing techniques such as feature scaling, encoding categorical variables, and data transformation prepare the dataset for model training, ensuring compatibility with machine learning algorithms.\n",
        "\n",
        "6. **Feature Engineering:** Feature engineering strategies create new features, extract relevant information, and enhance predictive power, refining the dataset for intrusion detection analysis.\n",
        "\n",
        "7. **Model Building:**\n",
        "   - **XGBoost (XGB):** XGBoost is employed as a powerful gradient boosting algorithm known for its high performance in classification tasks. Its ability to handle complex relationships and large datasets makes it a valuable tool for intrusion detection.\n",
        "   - **Logistic Regression:** Logistic Regression is utilized for its simplicity and interpretability, making it an effective baseline model for binary classification tasks. It provides insights into the linear relationships between features and the target variable, aiding in understanding intrusion detection patterns.\n",
        "8. **Evaluation:** Model evaluation metrics such as accuracy, precision, recall, F1-score, and area under the receiver operating characteristic curve (AUC-ROC) provide insights into model performance and efficacy in detecting network intrusions.\n",
        "\n",
        "9. **Feature Importance:** Feature importance analysis identifies key factors contributing to intrusion detection, enabling prioritization of features and enhancing model interpretability.\n",
        "\n",
        "10. **Results:** The analysis presents strengths and limitations of different machine learning models, discusses insights gained, and outlines recommendations for improving network intrusion detection strategies.\n",
        "\n",
        "This exploration into the NSL-KDD dataset navigates through the complexities of network intrusion detection, leveraging machine learning techniques to fortify defenses against cyber threats.\n",
        "\n"
      ],
      "metadata": {
        "id": "C5rZwoPUbIcH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. IMPORT LIBRARIES"
      ],
      "metadata": {
        "id": "ou8f5h2JbIcI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore') # 忽略警告訊息\n",
        "# 在 notebook 中顯示圖片\n",
        "%matplotlib inline\n",
        "pd.set_option('display.float_format', lambda x: '%.3f' % x) # 設定 pandas 顯示浮點數格式\n",
        "plt.rcParams[\"figure.figsize\"] = (10,6)  # 設定 matplotlib 圖形大小"
      ],
      "metadata": {
        "id": "OICilBdybIcI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. READ DATASET"
      ],
      "metadata": {
        "id": "xd4y54eLbIcI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_0 = pd.read_csv(\"KDDTrain+.txt\")\n",
        "df= df_0.copy()\n",
        "df.head() # 顯示資料集前五行"
      ],
      "metadata": {
        "scrolled": true,
        "id": "K3uK_QzybIcI",
        "outputId": "f0f813a8-8595-482e-d1ab-6d78129cf063",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'KDDTrain+.txt'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-2c2cbbdc94e2>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"KDDTrain+.txt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mdf_0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 顯示資料集前五行\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'KDDTrain+.txt'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2.1 ADJUST COLUMNS"
      ],
      "metadata": {
        "id": "UdfTprA_bIcI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 定義資料集的欄位名稱\n",
        "columns = (['duration'\n",
        ",'protocol_type'\n",
        ",'service'\n",
        ",'flag'\n",
        ",'src_bytes'\n",
        ",'dst_bytes'\n",
        ",'land'\n",
        ",'wrong_fragment'\n",
        ",'urgent'\n",
        ",'hot'\n",
        ",'num_failed_logins'\n",
        ",'logged_in'\n",
        ",'num_compromised'\n",
        ",'root_shell'\n",
        ",'su_attempted'\n",
        ",'num_root'\n",
        ",'num_file_creations'\n",
        ",'num_shells'\n",
        ",'num_access_files'\n",
        ",'num_outbound_cmds'\n",
        ",'is_host_login'\n",
        ",'is_guest_login'\n",
        ",'count'\n",
        ",'srv_count'\n",
        ",'serror_rate'\n",
        ",'srv_serror_rate'\n",
        ",'rerror_rate'\n",
        ",'srv_rerror_rate'\n",
        ",'same_srv_rate'\n",
        ",'diff_srv_rate'\n",
        ",'srv_diff_host_rate'\n",
        ",'dst_host_count'\n",
        ",'dst_host_srv_count'\n",
        ",'dst_host_same_srv_rate'\n",
        ",'dst_host_diff_srv_rate'\n",
        ",'dst_host_same_src_port_rate'\n",
        ",'dst_host_srv_diff_host_rate'\n",
        ",'dst_host_serror_rate'\n",
        ",'dst_host_srv_serror_rate'\n",
        ",'dst_host_rerror_rate'\n",
        ",'dst_host_srv_rerror_rate'\n",
        ",'attack'\n",
        ",'level'])\n",
        "\n",
        "df.columns = columns"
      ],
      "metadata": {
        "id": "mVVgYf6FbIcJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We don't have the names of the features from the given dataset so i adjust the columns from : https://www.kaggle.com/code/timgoodfellow/nsl-kdd-explorations"
      ],
      "metadata": {
        "id": "IR8e6tmibIcJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(5)"
      ],
      "metadata": {
        "id": "iftmlckvbIcJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2.2 INSIGHTS"
      ],
      "metadata": {
        "id": "ZJ5IeFKYbIcJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.info() # 顯示資料集的資訊，包括欄位名稱、非空值數量和資料類型"
      ],
      "metadata": {
        "id": "ruwykGCHbIcJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have different types of dtypes, we need encoding, doesn't seem like we have null values but we will check"
      ],
      "metadata": {
        "id": "Hh_Hp3E_bIcJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe().T # 顯示資料集的描述性統計資訊，轉置以便閱讀"
      ],
      "metadata": {
        "id": "9ITGzu1bbIcK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are some outlier values, but we will check if it's too much"
      ],
      "metadata": {
        "id": "KoCdft7HbIcK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. DATA CLEANING"
      ],
      "metadata": {
        "id": "l4qZcHYVbIcK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3.1 NULL VALUES"
      ],
      "metadata": {
        "id": "DHkO_PACbIcK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "D9sEqOBEbIcK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset doesn't contain any null value"
      ],
      "metadata": {
        "id": "-lspCI5rbIcK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#helper function for deeper analysis\n",
        "def unique_values(df, columns):\n",
        "    \"\"\"Prints unique values and their counts for specific columns in the DataFrame.\"\"\"\n",
        "\n",
        "    for column_name in columns:\n",
        "        print(f\"Column: {column_name}\\n{'-'*30}\")\n",
        "        unique_vals = df[column_name].unique()\n",
        "        value_counts = df[column_name].value_counts()\n",
        "        print(f\"Unique Values ({len(unique_vals)}): {unique_vals}\\n\")\n",
        "        print(f\"Value Counts:\\n{value_counts}\\n{'='*40}\\n\")"
      ],
      "metadata": {
        "id": "SD6VG7JlbIcK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cat_features = df.select_dtypes(include='object').columns\n",
        "unique_values(df, cat_features)"
      ],
      "metadata": {
        "id": "f-Y0VqY-bIcK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Further analysis will be in EDA-VISAULAZTION part about these column's impacts on Attacks"
      ],
      "metadata": {
        "id": "2lTWztIybIcK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3.2 DUPLICATES"
      ],
      "metadata": {
        "id": "rEU7tLBZbIcK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.duplicated().sum()"
      ],
      "metadata": {
        "id": "ghCuJTvEbIcK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset doesn't contain any duplicated row"
      ],
      "metadata": {
        "id": "Uwnq-WmxbIcK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3.3 OUTLIERS"
      ],
      "metadata": {
        "id": "_RMWBq1LbIcK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "5zmEzuAmbIcK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(20, 40))\n",
        "df.plot(kind='box', subplots=True, layout=(8, 5), figsize=(20, 40))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "yaLJGH89bIcK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There is no too much outlier to misslead the model so i will not drop the outliers"
      ],
      "metadata": {
        "id": "1ba42cvsbIcK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3.4 CLASSIFY ATTACK OR NOT"
      ],
      "metadata": {
        "id": "Onr1X5CCbIcL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "attack_n = []\n",
        "for i in df.attack :\n",
        "  if i == 'normal':\n",
        "    attack_n.append(\"normal\")\n",
        "  else:\n",
        "    attack_n.append(\"attack\")\n",
        "df['attack'] = attack_n"
      ],
      "metadata": {
        "id": "AZ0TpwK0bIcL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['attack'].unique()"
      ],
      "metadata": {
        "id": "XsgQn_yrbIcL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. EDA - VISUALIZATIONS"
      ],
      "metadata": {
        "id": "SVS08SdDbIcL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.hist(bins=43,figsize=(20,30));"
      ],
      "metadata": {
        "id": "G4Ese-yybIcL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "General visualization in order to get insights"
      ],
      "metadata": {
        "id": "-Q2gXnXWbIcL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4.1 Protocol Type"
      ],
      "metadata": {
        "id": "hUp2AvXcbIcL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(16,4))\n",
        "sns.countplot(x='attack',data=df,hue='protocol_type')\n",
        "plt.xticks(rotation=45)\n",
        "plt.title('Attack Counts over Protocol Types',fontdict={'fontsize':16})\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3Gq2JAU4bIcL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# So we can see that most of the attacks are from tcp, then udp, and least attack comes from icmp"
      ],
      "metadata": {
        "id": "gqvry6qibIcL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"protocol_type\"].value_counts(normalize=True)"
      ],
      "metadata": {
        "id": "QpZ3Y_I6bIcL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4.2 Service used general"
      ],
      "metadata": {
        "id": "odHtzFxXbIcV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(20, 8))  # Adjusted figure size\n",
        "ax = sns.countplot(x='service', data=df)\n",
        "ax.set_xticklabels(ax.get_xticklabels(), rotation=45, ha=\"right\")  # Rotated labels\n",
        "plt.xlabel('Service')\n",
        "plt.ylabel('Count')\n",
        "plt.title('Count of Services')\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "cODL7G0JbIcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Services most used in general follows as, http,private,domain_u,smtp, ftp,other.."
      ],
      "metadata": {
        "id": "Q9845BSJbIcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4.3 Service used effect on attacks"
      ],
      "metadata": {
        "id": "tmiqiVh9bIcV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(20, 8))  # Adjusted figure size\n",
        "ax = sns.countplot(x='service', hue='attack', data=df)\n",
        "ax.set_xticklabels(ax.get_xticklabels(), rotation=45, ha=\"right\")  # Rotated labels\n",
        "plt.xlabel('Service')\n",
        "plt.ylabel('Count')\n",
        "plt.title('Distribution of Attacks by Service')\n",
        "plt.legend(title='Attack Type')\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "jGaUF2G3bIcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#we can see that private attacks is most common service"
      ],
      "metadata": {
        "id": "KdNLKGOabIcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4.4 Kernel Density Estimate (KDE) Plot of Duration by Flag"
      ],
      "metadata": {
        "id": "p1Gh7JTKbIcV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.displot(\n",
        "    data=df,\n",
        "    x=\"duration\",\n",
        "    hue=\"flag\",\n",
        "    kind=\"kde\",\n",
        "    height=6,\n",
        "    multiple=\"fill\",\n",
        "    clip=(0, None),\n",
        "    palette=\"ch:rot=-.25,hue=1,light=.75\",\n",
        ")\n",
        "plt.title('Kernel Density Estimate (KDE) Plot of Duration by Flag')\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "a_jvRQCkbIcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4.5 Distribution of Attack Types by Guest Login"
      ],
      "metadata": {
        "id": "SfVXM4xgbIcV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "sns.countplot(x='is_guest_login', hue='attack', data=df, palette='Set2')\n",
        "plt.xlabel('Is Guest Login')\n",
        "plt.ylabel('Count')\n",
        "plt.title('Distribution of Attack Types by Guest Login')\n",
        "plt.legend(title='Attack Type')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ydQK5y6zbIcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "we can clearly say that attacks are comes when guest is not login"
      ],
      "metadata": {
        "id": "3B_pjY3cbIcV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. PREPROCESSING"
      ],
      "metadata": {
        "id": "-kh6-I6AbIcV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5.1 ENCODING"
      ],
      "metadata": {
        "id": "RfOHMxKcbIcW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cat_features = df.select_dtypes(include='object').columns\n",
        "cat_features"
      ],
      "metadata": {
        "scrolled": true,
        "id": "Clrt7YHKbIcW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import preprocessing\n",
        "le=preprocessing.LabelEncoder()\n",
        "clm=['protocol_type', 'service', 'flag', 'attack']\n",
        "for x in clm:\n",
        "    df[x]=le.fit_transform(df[x])"
      ],
      "metadata": {
        "id": "Fq4qg3eAbIcW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5.2 TRAIN-TEST-SPLIT"
      ],
      "metadata": {
        "id": "xopNE0jSbIcW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = df.drop([\"attack\"], axis=1)\n",
        "y = df[\"attack\"]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.1,random_state=43)"
      ],
      "metadata": {
        "id": "oQPskfaZbIcW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_index = X_train.columns\n",
        "train_index"
      ],
      "metadata": {
        "id": "YlqiWy1LbIcW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5.3 Feature Engineering"
      ],
      "metadata": {
        "id": "aMEGittqbIcW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import mutual_info_classif\n",
        "mutual_info = mutual_info_classif(X_train, y_train)\n",
        "mutual_info = pd.Series(mutual_info)\n",
        "mutual_info.index = train_index\n",
        "mutual_info.sort_values(ascending=False)"
      ],
      "metadata": {
        "id": "2JFTQ1_hbIcW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mutual_info.sort_values(ascending=False).plot.bar(figsize=(20, 5));"
      ],
      "metadata": {
        "id": "djTRGwQsbIcW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5.4 Feature Selection"
      ],
      "metadata": {
        "id": "bj0yuNjxbIcW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import SelectKBest\n",
        "Select_features = SelectKBest(mutual_info_classif, k=30)\n",
        "Select_features.fit(X_train, y_train)\n",
        "train_index[Select_features.get_support()]"
      ],
      "metadata": {
        "id": "7tnK6x3abIcW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "columns=['duration', 'protocol_type', 'service', 'flag', 'src_bytes',\n",
        "       'dst_bytes', 'wrong_fragment', 'hot', 'logged_in', 'num_compromised',\n",
        "       'count', 'srv_count', 'serror_rate', 'srv_serror_rate', 'rerror_rate']\n",
        "\n",
        "#We will continue our model with top 15 features, because dataset is big enough\n",
        "\n",
        "X_train=X_train[columns]\n",
        "X_test=X_test[columns]"
      ],
      "metadata": {
        "id": "CKtRk664bIcW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5.5 Scaling"
      ],
      "metadata": {
        "id": "glBl0bBwbIcW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test) # we use only transform in order to prevent data leakage"
      ],
      "metadata": {
        "id": "ajscTsHPbIcW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. MODEL BUILD"
      ],
      "metadata": {
        "id": "ppT9Ft5gbIcW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from xgboost import XGBClassifier"
      ],
      "metadata": {
        "id": "xVFXy8nvbIcW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "XGBoost_model = XGBClassifier(random_state = 42)\n",
        "Logistic_model = LogisticRegression(random_state=42)"
      ],
      "metadata": {
        "id": "4jKEdrFIbIcW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "XGBoost = XGBoost_model.fit(X_train,y_train)"
      ],
      "metadata": {
        "id": "CeTAi7oybIcW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Logistic = Logistic_model.fit(X_train,y_train)"
      ],
      "metadata": {
        "id": "Oy0m1F4ZbIcW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, recall_score, precision_score, f1_score, roc_auc_score"
      ],
      "metadata": {
        "id": "vkw6OVePbIcX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#it's a helper function in order to evaluate our model if it's overfit or underfit.\n",
        "def eval_metric(model, X_train, y_train, X_test, y_test):\n",
        "    y_train_pred = model.predict(X_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    print(\"Test_Set\")\n",
        "    print(confusion_matrix(y_test, y_pred))\n",
        "    print(classification_report(y_test, y_pred))\n",
        "    print()\n",
        "    print(\"Train_Set\")\n",
        "    print(confusion_matrix(y_train, y_train_pred))\n",
        "    print(classification_report(y_train, y_train_pred))"
      ],
      "metadata": {
        "id": "WFYWFlc0bIcX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eval_metric(Logistic_model, X_train, y_train, X_test, y_test)"
      ],
      "metadata": {
        "id": "AhnBUt6sbIcX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eval_metric(XGBoost_model, X_train, y_train, X_test, y_test)"
      ],
      "metadata": {
        "id": "2r749wxKbIcX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So we can see that ensemble methods such as xgboost,adaboost,gradientboosts has more accurace scores over logistic regression in bigger datasets.\n",
        "\n",
        "It doesn't neccessary but we will do hyperparameter tuning in order to fit the model with best parameters, i would like to remember that xgboost has cross-validation has itself"
      ],
      "metadata": {
        "id": "t7yCSsZvbIcX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6.1 HYPERPARAMETER TUNING"
      ],
      "metadata": {
        "id": "_XNM-uKZbIcX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid = {\n",
        "    \"n_estimators\": [50,64,100,128],\n",
        "    \"max_depth\": [2, 3, 4,5,6],\n",
        "    \"learning_rate\": [0.01,0,0.03, 0.05, 0.1],\n",
        "    \"subsample\": [0.5, 0.8],\n",
        "    \"colsample_bytree\": [0.5, 0.8]\n",
        "}"
      ],
      "metadata": {
        "id": "a_c-AyIdbIcX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "XGB_model = XGBClassifier(random_state=42) #initialize the model\n",
        "\n",
        "XGB_grid_model = GridSearchCV(XGB_model,\n",
        "                        param_grid,\n",
        "                        scoring=\"f1\",\n",
        "                        n_jobs=-1,\n",
        "                        return_train_score=True).fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "XNiyucM3bIcX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "XGB_grid_model.best_score_"
      ],
      "metadata": {
        "id": "ZHlpiFVcbIcX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "XGB_grid_model.best_params_"
      ],
      "metadata": {
        "scrolled": true,
        "id": "HNelFrxLbIcX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6.2 FINAL MODEL"
      ],
      "metadata": {
        "id": "-RXIm8wEbIcX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "XGB_model = XGBClassifier(\n",
        "    colsample_bytree=0.5,\n",
        "    learning_rate=0.1,\n",
        "    max_depth=6,\n",
        "    n_estimators=128,\n",
        "    subsample=0.8\n",
        ")\n",
        "\n",
        "# Fit the classifier to your data\n",
        "XGB_model.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "cdfNkqwabIcX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6.3 EVALUATION"
      ],
      "metadata": {
        "id": "Zgw2Kf1jbIcX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = XGB_model.predict(X_test)\n",
        "y_pred_proba = XGB_model.predict_proba(X_test)\n",
        "\n",
        "xgb_f1 = f1_score(y_test, y_pred)\n",
        "xgb_recall = recall_score(y_test, y_pred)\n",
        "xgb_auc = roc_auc_score(y_test, y_pred_proba[:,1])\n"
      ],
      "metadata": {
        "id": "tjwiaZ0sbIcX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xgb_auc"
      ],
      "metadata": {
        "id": "C4h_EN6obIcX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import RocCurveDisplay\n",
        "\n",
        "RocCurveDisplay.from_estimator(XGB_model, X_test, y_test);"
      ],
      "metadata": {
        "id": "Jks6EkQnbIcX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eval_metric(XGB_model, X_train, y_train, X_test, y_test)"
      ],
      "metadata": {
        "id": "YHhIUMHnbIcX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7. FEATURE IMPORTANCE"
      ],
      "metadata": {
        "id": "pn-hRY8ebIcX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = XGB_model\n",
        "model.feature_importances_\n",
        "\n",
        "feats = pd.DataFrame(index=X[columns].columns, data= model.feature_importances_, columns=['XGB_importance'])\n",
        "ada_imp_feats = feats.sort_values(\"XGB_importance\", ascending = False)\n",
        "ada_imp_feats"
      ],
      "metadata": {
        "id": "NX6UyLXLbIcY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred"
      ],
      "metadata": {
        "id": "1NJYQEV-bIcY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_string = le.inverse_transform(y_pred)\n",
        "y_pred_string"
      ],
      "metadata": {
        "id": "OH40CVSwbIcY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the countplot\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.countplot(x=y_pred_string, palette=\"pastel\")\n",
        "\n",
        "# Add labels and title\n",
        "plt.xlabel(\"Attack Type\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.title(\"Distribution of Attack Types\")\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-2qbXfbJbIcY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}